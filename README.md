âœ¨ Signfy âœ¨


Signfy is a real-time Sign Language to Speech converter that bridges communication gaps between hearing-impaired individuals and others by translating hand gestures into audible speech.

ğŸš€ Features

ğŸ–ï¸ Real-time hand gesture recognition using MediaPipe

ğŸ—£ï¸ Converts recognized signs into speech using pyttsx3

ğŸ’» Optional Streamlit GUI for easy interaction

âš¡ Lightweight and works on standard laptops with webcam

ğŸ¯ Can be extended to support multiple languages and additional gestures

ğŸ› ï¸ Tech Stack

Python 3.x

OpenCV â€“ for video capture and processing

MediaPipe â€“ for hand landmark detection

NumPy â€“ for data handling and calculations

pyttsx3 â€“ text-to-speech conversion

Streamlit (optional) â€“ web-based interface

ğŸ“‚ Installation

Clone the repository:

git clone https://github.com/Chaturvediharsh123/signfy.git
cd signfy


Install dependencies:

pip install -r requirements.txt

â–¶ï¸ Usage

Run the app:

python app.py


Or with Streamlit interface:

streamlit run multi.py


How it works:

Webcam captures hand gestures in real-time

MediaPipe detects key hand landmarks

Classifier predicts the corresponding sign

pyttsx3 converts recognized signs into speech

ğŸ“¦ Requirements
opencv-python
mediapipe
numpy
pyttsx3
streamlit
protobuf==3.20.*

ğŸ§  How it Works

Hand Detection: MediaPipe identifies hand landmarks from webcam feed.

Sign Classification: Positions of fingers and hand gestures are analyzed to classify signs.

Speech Conversion: Recognized signs are converted to speech using pyttsx3.

âœ¨ Inspiration

Signfy was created to enhance communication accessibility for hearing-impaired individuals. It demonstrates how AI and computer vision can bridge communication gaps and make everyday interactions easier.

ğŸ¤ Contributing

Contributions are welcome! Ideas for improvement:

Add more gestures to the classifier

Multi-language support for speech

Optimize real-time performance

ğŸ“œ License

This project is licensed under the MIT License.
